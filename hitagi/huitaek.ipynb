{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ˜¸ <b>ê³µê²¹ì¶˜ë°°</b>\n",
    "\n",
    "ì•Œë¦¬ì˜¤\n",
    "https://alio.go.kr/\n",
    "\n",
    "ì¡ì•Œë¦¬ì˜¤\n",
    "https://job.alio.go.kr/\n",
    "\n",
    "ì¡í”Œë˜ë‹›\n",
    "https://www.jobplanet.co.kr/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š <b>ë¼ì´ë¸ŒëŸ¬ë¦¬</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import platform\n",
    "\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver import ActionChains\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.common.by import By\n",
    "\n",
    "#í•œê¸€ í°íŠ¸\n",
    "if platform.system()== 'Windows' :\n",
    "    plt.rc('font', family='NanumGothic')\n",
    "else:\n",
    "    plt.rc('font', family = 'AppleGothic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ›  <b>ì•Œë¦¬ì˜¤ ê³µê³µê¸°ê´€ ì½”ë“œ í¬ë¡¤ë§</b>\n",
    "\n",
    "\n",
    "ì•Œë¦¬ì˜¤ 370ì—¬ê°œ ê³µê³µê¸°ê´€ ìŠ¤í¬ë¦½íŠ¸ ì‘ë™ ë‚´ë¶€ url ì½”ë“œ í¬ë¡¤ë§\n",
    "\n",
    "\n",
    "ì•Œë¦¬ì˜¤ - [í•­ëª© ë³„ ê³µì‹œ] - [ì§ì› í‰ê· ë³´ìˆ˜ í˜„í™©] ì •ë³´ëŠ” ë¬¸ì„œ ìŠ¤í¬ë¦½íŠ¸ë¡œ ë™ì‘, ë°”ë¡œ í¬ë¡¤ë§ í•  ìˆ˜ ì—†ìŒ.\n",
    "\n",
    "\n",
    "ê° ê³µê³µê¸°ê´€ ë³„ ë‚´ë¶€ url ì½”ë“œì—ì„œ ê·œì¹™ì„ ì°¾ì•„ í¬ë¡¤ë§ (C0001 ~ C1370)\n",
    "\n",
    "\n",
    "+ https://alio.go.kr/item/itemReportTerm.do?apbaId=C0001&reportFormRootNo=20601#toc-124\n",
    "\n",
    "\n",
    "script ì— disclosureNo('2021041302190478') í˜•ì‹ì˜ ê³µê°œ ë²ˆí˜¸ ë°œê²¬, html ë¬¸ì„œì— ì§ì ‘ ì ‘ê·¼í•´ í¬ë¡¤ë§ í•  ìˆ˜ ìˆê²Œ ë¨.\n",
    "\n",
    "\n",
    "+ https://alio.go.kr/upload/disclosure/2021/04/13/2021041302190478/doc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì•Œë¦¬ì˜¤ 372ê°œ ê³µê³µê¸°ê´€ ë‚´ë¶€ url ì½”ë“œ í¬ë¡¤ë§ (7ë¶„ 40ì´ˆ ê±¸ë¦¼)\n",
    "\n",
    "codedict = {\"institution\":[], \"code\":[]}\n",
    "\n",
    "for i in range(1, 1370):\n",
    "    \n",
    "    if i < 10 :\n",
    "        urlcode = 'C000{}'.format(i)\n",
    "    elif 10 <= i | i < 100 :\n",
    "        urlcode = 'C00{}'.format(i)\n",
    "    elif 100 <= i | i < 1000 :\n",
    "        urlcode = 'C0{}'.format(i)\n",
    "    elif 1000 <= i | i < 10000 :\n",
    "        urlcode = 'C{}'.format(i)\n",
    "\n",
    "    url = 'https://alio.go.kr/item/itemReportTerm.do?apbaId={}&reportFormRootNo=20601'.format(urlcode)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        #print(response.status_code)\n",
    "    else :\n",
    "        print(response.status_code)\n",
    "\n",
    "    institution = soup.select_one('#p_header_wrap > div.hl_area > div > div > span')\n",
    "\n",
    "    if institution != None:\n",
    "        codedict['institution'].append(institution.text)\n",
    "        codedict['code'].append(urlcode)\n",
    "        print('institution: ' + institution.text + ', code: ' + urlcode)\n",
    "\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì¶”ì¶œí•œ url ì½”ë“œ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(codedict)\n",
    "df\n",
    "\n",
    "# í•œêµ­ê´‘í•´ê´‘ì—…ê³µë‹¨(2021.12.08 ì§€ì •) ì´ì „ ë°ì´í„° ì—†ìŒ -> ì‚­ì œ\n",
    "# **í•œêµ­ìœ¨ë„ ë°ì´í„° ì—†ìŒ -> ì‚­ì œ\n",
    "df.drop(index=226, axis=0, inplace=True)\n",
    "df.drop(index=371, axis=0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# csv íŒŒì¼ë¡œ ì €ì¥\n",
    "df.to_csv('institution_code.csv', index=False)\n",
    "\n",
    "# ì œëŒ€ë¡œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "institution_code = pd.read_csv('institution_code.csv')\n",
    "institution_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institution_code = pd.read_csv('institution_code.csv')\n",
    "institution_code\n",
    "institution_code[institution_code['institution']=='**í•œêµ­ìœ¨ë„']\n",
    "\n",
    "institution_code.drop(index=226, axis=0, inplace=True)\n",
    "institution_code.drop(index=371, axis=0, inplace=True)\n",
    "institution_code.reset_index(drop=True, inplace=True)\n",
    "institution_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ›  <b>ì•Œë¦¬ì˜¤ ì •ë³´ í¬ë¡¤ë§</b>\n",
    "disclosureNo('2021041302190478') í˜•ì‹ì˜ ê³µê°œ ë²ˆí˜¸ë¥¼ í†µí•´ ì•Œë¦¬ì˜¤ html ë¬¸ì„œ í¬ë¡¤ë§ \n",
    "\n",
    "https://alio.go.kr/upload/disclosure/2021/04/13/2021041302190478/doc.html\n",
    "\n",
    "+ ì‹ ì…ì‚¬ì› ì´ˆì„ (new_sal)\n",
    "+ ì§ì› í‰ê· ì—°ë´‰ (avg_sal)\n",
    "+ í‰ê·  ê·¼ì†ì—°ìˆ˜ (y_service)\n",
    ">ê°ê° 6ë…„ì¹˜ ë°ì´í„° í¬ë¡¤ë§(2016, 2017, 2018, 2019, 2020, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'êµ­ë¦½í•´ì–‘ê³¼í•™ê´€'\n",
    "urlword = 'C0003'\n",
    "#print(urlword) # C1333\n",
    "\n",
    "url = 'https://alio.go.kr/item/itemReportTerm.do?apbaId={}&reportFormRootNo=20601'.format(urlword)\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #print(response.status_code)\n",
    "else :\n",
    "    print(response.status_code)\n",
    "\n",
    "\n",
    "script = soup.select(\"body > script:nth-child(4)\")\n",
    "str(script[0])\n",
    "regex=re.compile(\"disclosureNo:\\\"(\\d+)\\\"\")\n",
    "disclosureNo = regex.findall(str(script[0]))[0]\n",
    "disclosureyear = disclosureNo[:4]\n",
    "disclosuremonth = disclosureNo[4:6]\n",
    "disclosureday = disclosureNo[6:8]\n",
    "\n",
    "url = 'https://alio.go.kr/upload/disclosure/{}/{}/{}/{}/doc.html'.format(disclosureyear, disclosuremonth, disclosureday, disclosureNo)\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #print(response.status_code)\n",
    "else :\n",
    "    print(response.status_code)\n",
    "\n",
    "address = soup.find(text=\"1ì¸ë‹¹ í‰ê·  ë³´ìˆ˜ì•¡\")\n",
    "neu = address.parent\n",
    "neu = neu.parent\n",
    "print(neu.text.strip().split('\\n'))\n",
    "\n",
    "address = soup.find(text=\"í‰ê· ê·¼ì†ì—°ìˆ˜(ê°œì›”)\")\n",
    "neu2 = address.parent\n",
    "neu2 = neu2.parent\n",
    "print(neu2.text.strip().split('\\n'))\n",
    "\n",
    "address = soup.find(text=\"í•©ê³„\")\n",
    "neu3 = address.parent\n",
    "neu3 = neu3.parent\n",
    "print(neu3.text.strip().split('\\n'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetAlioInfo :\n",
    "    \n",
    "    def __init__(self, keyword) :\n",
    "        urlword = institution_code[institution_code['institution']==keyword]['code'].values[0]\n",
    "\n",
    "        url = 'https://alio.go.kr/item/itemReportTerm.do?apbaId={}&reportFormRootNo=20601'.format(urlword)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        html = response.text\n",
    "        self.soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        script = self.soup.select(\"body > script:nth-child(4)\")\n",
    "        str(script[0])\n",
    "        regex=re.compile(\"disclosureNo:\\\"(\\d+)\\\"\")\n",
    "        disclosureNo = regex.findall(str(script[0]))[0]\n",
    "        disclosureyear = disclosureNo[:4]\n",
    "        disclosuremonth = disclosureNo[4:6]\n",
    "        disclosureday = disclosureNo[6:8]\n",
    "\n",
    "        url = 'https://alio.go.kr/upload/disclosure/{}/{}/{}/{}/doc.html'.format(disclosureyear, disclosuremonth, disclosureday, disclosureNo)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            html = response.text\n",
    "            self.soup = BeautifulSoup(html, 'html.parser')\n",
    "            #print(response.status_code)\n",
    "        else :\n",
    "            print(response.status_code)\n",
    "    \n",
    "    def get_new_sal(self) :\n",
    "        address = self.soup.find(\"a\", text=\"2. ì‹ ì…ì‚¬ì› ì´ˆì„\").findNext(text=\"í•©ê³„\").parent.parent\n",
    "        new_sal = address.text.strip().split('\\n')\n",
    "        new_sal[0] = 'ì‹ ì…ì‚¬ì› ì´ˆë´‰'\n",
    "        return(new_sal)\n",
    "\n",
    "    def get_avg_sal(self) :\n",
    "        address = self.soup.find(\"td\", text=\"ì •ê·œì§(ì¼ë°˜ì •ê·œì§)\").findNext(text=\"1ì¸ë‹¹ í‰ê·  ë³´ìˆ˜ì•¡\").parent.parent\n",
    "        avg_sal = address.text.strip().split('\\n')\n",
    "        return(avg_sal)\n",
    "\n",
    "    def get_y_service(self) :\n",
    "        address = self.soup.find(\"td\", text=\"ì •ê·œì§(ì¼ë°˜ì •ê·œì§)\").findNext(text=\"í‰ê· ê·¼ì†ì—°ìˆ˜(ê°œì›”)\").parent.parent\n",
    "        y_service = address.text.strip().split('\\n')\n",
    "        return(y_service)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì•Œë¦¬ì˜¤ ì§ì› í‰ê· ì—°ë´‰ í¬ë¡¤ë§+ì €ì¥\n",
    "ì§ì› í‰ê· ì—°ë´‰(avg_sal) -> alio_avg_sal.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sal_dict = {\"institution\":[], \"avg16\":[], \"avg17\":[], \"avg18\":[], \"avg19\":[], \"avg20\":[], \"avg21\":[]}\n",
    "\n",
    "i = 1\n",
    "for keyword in institution_code['institution']:\n",
    "    a = GetAlioInfo(keyword)\n",
    "    templist = a.get_avg_sal()\n",
    "    avg_sal_dict['institution'].append(keyword)\n",
    "    avg_sal_dict['avg16'].append(templist[1].strip().replace(',',''))\n",
    "    avg_sal_dict['avg17'].append(templist[2].strip().replace(',',''))\n",
    "    avg_sal_dict['avg18'].append(templist[3].strip().replace(',',''))\n",
    "    avg_sal_dict['avg19'].append(templist[4].strip().replace(',',''))\n",
    "    avg_sal_dict['avg20'].append(templist[5].strip().replace(',',''))\n",
    "    avg_sal_dict['avg21'].append(templist[6].strip().replace(',',''))\n",
    "    percentage = round(i / (len(institution_code['institution'])+1) * 100, 2)\n",
    "    print(percentage,'% ', keyword, templist[1:6])\n",
    "    i += 1\n",
    "\n",
    "df = pd.DataFrame(avg_sal_dict)\n",
    "df.to_csv('alio_avg_sal.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì•Œë¦¬ì˜¤ ì‹ ì…ì‚¬ì› ì´ˆë´‰ í¬ë¡¤ë§+ì €ì¥\n",
    "ì‹ ì…ì‚¬ì› ì´ˆë´‰(new_sal) -> alio_new_sal.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sal_dict = {\"institution\":[], \"new16\":[], \"new17\":[], \"new18\":[], \"new19\":[], \"new20\":[], \"new21\":[]}\n",
    "\n",
    "i = 1\n",
    "for keyword in institution_code['institution']:\n",
    "    a = GetAlioInfo(keyword)\n",
    "    templist = a.get_new_sal()\n",
    "    new_sal_dict['institution'].append(keyword)\n",
    "    new_sal_dict['new16'].append(templist[1].strip().replace(',',''))\n",
    "    new_sal_dict['new17'].append(templist[2].strip().replace(',',''))\n",
    "    new_sal_dict['new18'].append(templist[3].strip().replace(',',''))\n",
    "    new_sal_dict['new19'].append(templist[4].strip().replace(',',''))\n",
    "    new_sal_dict['new20'].append(templist[5].strip().replace(',',''))\n",
    "    new_sal_dict['new21'].append(templist[6].strip().replace(',',''))\n",
    "    percentage = round(i / (len(institution_code['institution'])+1) * 100, 2)\n",
    "    print(percentage,'% ', keyword, templist[1:6])\n",
    "    i += 1\n",
    "    \n",
    "df = pd.DataFrame(new_sal_dict)\n",
    "df.to_csv('alio_new_sal.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì•Œë¦¬ì˜¤ í‰ê·  ê·¼ì†ë…„ìˆ˜ í¬ë¡¤ë§+ì €ì¥\n",
    "í‰ê·  ê·¼ì†ë…„ìˆ˜(y_service) -> alio_y_service.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_service_dict = {\"institution\":[], \"ser16\":[], \"ser17\":[], \"ser18\":[], \"ser19\":[], \"ser20\":[], \"ser21\":[]}\n",
    "\n",
    "i = 1\n",
    "for keyword in institution_code['institution']:\n",
    "    a = GetAlioInfo(keyword)\n",
    "    templist = a.get_y_service()\n",
    "    y_service_dict['institution'].append(keyword)\n",
    "    y_service_dict['ser16'].append(templist[1].strip().replace(',',''))\n",
    "    y_service_dict['ser17'].append(templist[2].strip().replace(',',''))\n",
    "    y_service_dict['ser18'].append(templist[3].strip().replace(',',''))\n",
    "    y_service_dict['ser19'].append(templist[4].strip().replace(',',''))\n",
    "    y_service_dict['ser20'].append(templist[5].strip().replace(',',''))\n",
    "    y_service_dict['ser21'].append(templist[6].strip().replace(',',''))\n",
    "    percentage = round(i / (len(institution_code['institution'])+1) * 100, 2)\n",
    "    print(percentage,'% ', keyword, templist[1:6])\n",
    "    i += 1\n",
    "\n",
    "df = pd.DataFrame(y_service_dict)\n",
    "df.to_csv('alio_y_service.csv')\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› <b> ì¡ì•Œë¦¬ì˜¤ </b>\n",
    "\n",
    "https://job.alio.go.kr/recruit.do\n",
    "\n",
    "ê³µê³µê¸°ê´€ ì±„ìš© ì •ë³´ í¬ë¡¤ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {\"institution\":[], \"title\":[], \"region\":[], \"type\":[], \"start_date\":[], \"end_date\":[], \"new_sal\":[], \"avg_sal\":[], \"rate\":[]}\n",
    "\n",
    "def current_employment():\n",
    "\n",
    "    classification = input(\"\"\"\n",
    "    ì§ì¢…ì„ ì„ íƒí•´ ì£¼ì„¸ìš”: \n",
    "    1. ê²½ì˜ì‚¬ë¬´,     2. ì„œë¹„ìŠ¤ ,    3. ICT,    4. êµìœ¡/ì—°êµ¬,    5. ì‚°ì—…,    6. ì „ë¶€\"\"\")\n",
    "    if classification == 'ê²½ì˜ì‚¬ë¬´':\n",
    "        classification = '&detail_code=R600001&detail_code=R600002&detail_code=R600003'\n",
    "    elif classification == 'ì„œë¹„ìŠ¤':\n",
    "        classification = '&detail_code=R600005&detail_code=R600006&detail_code=R600007&detail_code=R600008&detail_code=R600009&detail_code=R600010&detail_code=R600011&detail_code=R600012&detail_code=R600013'\n",
    "    elif classification == 'ICT':\n",
    "        classification = '&detail_code=R600019&detail_code=R600020'\n",
    "    elif classification == 'êµìœ¡/ì—°êµ¬':\n",
    "        classification = '&detail_code=R600004&detail_code=R600025'\n",
    "    elif classification == 'ì‚°ì—…':\n",
    "        classification = '&detail_code=R600014&detail_code=R600015&detail_code=R600016&detail_code=R600017&detail_code=R600018&detail_code=R600021&detail_code=R600022&detail_code=R600023&detail_code=R600024'\n",
    "    elif classification == 'ì „ë¶€':\n",
    "        classification = ''\n",
    "    \n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "\n",
    "        url = 'https://job.alio.go.kr/recruit.do?pageNo={}&idx=&recruitYear=&recruitMonth={}&work_type=R1010&work_type=R1070&s_date=2021.12.08&e_date=2022.02.08&org_type=&org_name=&ing=2&title=&order=REG_DATE#'.format(page, classification)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            html = response.text\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            #print(response.status_code)\n",
    "        else :\n",
    "            print(response.status_code)\n",
    "\n",
    "        tbody = soup.select_one('#frm > table > tbody')\n",
    "        trs = tbody.select('tr')\n",
    "        \n",
    "        if len(tbody.text.strip()) == 0:\n",
    "            #print('neu~')  # ë‚´ìš© ì—†ëŠ” í˜ì´ì§€ê¹Œì§€ ì¶œë ¥ í›„ í™•ì¸ìš©\n",
    "            break\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.select(\"td\")\n",
    "            dictionary[\"institution\"].append(tds[3].text.replace('ì¬ë‹¨ë²•ì¸', '(ì¬)').strip())\n",
    "            dictionary[\"title\"].append(tds[2].text.replace('\\t', '').replace('\\r', '').replace('\\n', '').strip())\n",
    "            dictionary[\"region\"].append(tds[4].text.replace('\\t', '').replace('\\r', '').replace('\\n', '').strip())\n",
    "            dictionary[\"type\"].append(tds[5].text.replace('\\t', '').replace('\\r', '').replace('\\n', '').strip())\n",
    "            dictionary[\"start_date\"].append(tds[6].text)\n",
    "            dictionary[\"end_date\"].append(tds[7].text)\n",
    "\n",
    "            # JobPlanet ë¦¬ë·°\n",
    "            try:\n",
    "                keyword = tds[3].text.replace('ì¬ë‹¨ë²•ì¸', '(ì¬)').strip()\n",
    "                url = 'https://www.jobplanet.co.kr/search?_rs_act=search_history&_rs_con=seach&category=search_new&query={}'.format(keyword)\n",
    "\n",
    "                response = requests.get(url)\n",
    "\n",
    "                response.raise_for_status()\n",
    "                if response.status_code == 200:\n",
    "                    html = response.text\n",
    "                    soup = BeautifulSoup(html, 'html.parser')\n",
    "                    #print(response.status_code)\n",
    "                else :\n",
    "                    print(response.status_code)\n",
    "\n",
    "                result_card = soup.select_one('#mainContents > div:nth-child(1) > div > div.result_company_card > div.is_company_card > div:nth-child(1)')\n",
    "                rate = result_card.select_one('#mainContents > div:nth-child(1) > div > div.result_company_card > div.is_company_card > div:nth-child(1) > span.rate_ty02')\n",
    "                dictionary['rate'].append(float(rate.text.strip()))\n",
    "                print(rate.text)\n",
    "            except:\n",
    "                dictionary['rate'].append(None)\n",
    "        page += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_employment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dictionary)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrate = pd.concat([df['institution'], df['rate'], df['new_sal'],df['avg_sal']], axis=1)\n",
    "dfrate.drop_duplicates(inplace=True)\n",
    "dfrate.dropna(inplace=True)\n",
    "dfrate_top5 = dfrate.sort_values(['rate'], ascending=False).head(5)\n",
    "dfrate_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=15)\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "x = np.arange(len(dfrate_top5['institution']))\n",
    "\n",
    "plt.bar(x-0, dfrate_top5['rate']*10000, label='rate', color = 'b', width=0.2)\n",
    "plt.bar(x+0.2, dfrate_top5['new_sal'], label='new_sal', color = 'r', width=0.2)\n",
    "plt.bar(x+0.4, dfrate_top5['avg_sal'], label='avg_sal', color = 'g', width=0.2)\n",
    "plt.xticks(x, dfrate_top5['institution'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dictionary = {\"institution\":[], \"title\":[], \"region\":[], \"type\":[], \"start_date\":[], \"end_date\":[]}\n",
    "\n",
    "def get_all_employment():\n",
    "\n",
    "    classification = input(\"\"\"\n",
    "    ì§ì¢…ì„ ì„ íƒí•´ ì£¼ì„¸ìš”:\n",
    "    1. ê²½ì˜ì‚¬ë¬´\n",
    "    2. ì„œë¹„ìŠ¤\n",
    "    3. ICT\n",
    "    4. êµìœ¡/ì—°êµ¬ \"\"\")\n",
    "    if classification == 'ê²½ì˜ì‚¬ë¬´':\n",
    "        classification = '&detail_code=R600001&detail_code=R600002&detail_code=R600003'\n",
    "    elif classification == 'ì„œë¹„ìŠ¤':\n",
    "        classification = '&detail_code=R600005&detail_code=R600006&detail_code=R600007&detail_code=R600008&detail_code=R600009&detail_code=R600010&detail_code=R600011&detail_code=R600012&detail_code=R600013'\n",
    "    elif classification == 'ICT':\n",
    "        classification = '&detail_code=R600019&detail_code=R600020'\n",
    "    elif classification == 'êµìœ¡/ì—°êµ¬':\n",
    "        classification = '&detail_code=R600004&detail_code=R600025'\n",
    "    elif classification == 'ì‚°ì—…':\n",
    "        classification = '&detail_code=R600014&detail_code=R600015&detail_code=R600016&detail_code=R600017&detail_code=R600018&detail_code=R600021&detail_code=R600022&detail_code=R600023&detail_code=R600024'\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "\n",
    "        url = 'https://job.alio.go.kr/recruit.do?pageNo={}&idx=&recruitYear=&recruitMonth={}&work_type=R1010&work_type=R1070&s_date=2016.01.01&e_date=2022.02.08&org_type=&org_name=&title=&order=REG_DATE#'.format(page, classification)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            html = response.text\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            #print(response.status_code)\n",
    "        else :\n",
    "            print(response.status_code)\n",
    "\n",
    "        tbody = soup.select_one('#frm > table > tbody')\n",
    "        trs = tbody.select('tr')\n",
    "        \n",
    "        if len(tbody.text.strip()) == 0:\n",
    "            print('neu~')  # ë‚´ìš© ì—†ëŠ” í˜ì´ì§€ê¹Œì§€ ì¶œë ¥ í›„ í™•ì¸ìš©\n",
    "            break\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.select(\"td\")\n",
    "            all_dictionary[\"institution\"].append(tds[3].text.replace('ì¬ë‹¨ë²•ì¸', '(ì¬)').strip())\n",
    "            all_dictionary[\"title\"].append(tds[2].text.replace('\\t', '').replace('\\r', '').replace('\\n', '').strip())\n",
    "            all_dictionary[\"region\"].append(tds[4].text.replace('\\t', '').replace('\\r', '').replace('\\n', '').strip())\n",
    "            all_dictionary[\"type\"].append(tds[5].text.replace('\\t', '').replace('\\r', '').replace('\\n', '').strip())\n",
    "            all_dictionary[\"start_date\"].append(tds[6].text)\n",
    "            all_dictionary[\"end_date\"].append(tds[7].text)\n",
    "\n",
    "        page += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_employment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_dictionary)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_date'] = pd.to_datetime(df['start_date'], yearfirst= True)\n",
    "df['end_date'] = pd.to_datetime(df['end_date'], yearfirst= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "monthlist = []\n",
    "\n",
    "\n",
    "for i in range(1, 13):\n",
    "    monthlist.append(df[df['end_date'].dt.month==i]['institution'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "plt.bar(month, monthlist)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "099c82bb4ace82ade8ea00d06692c6005c84f3239a96c9207fc6992d929102eb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
