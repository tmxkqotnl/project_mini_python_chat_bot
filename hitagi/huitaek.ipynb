{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 😸 <b>공겹춘배</b>\n",
    "\n",
    "알리오\n",
    "https://alio.go.kr/\n",
    "\n",
    "잡알리오\n",
    "https://job.alio.go.kr/\n",
    "\n",
    "잡플래닛\n",
    "https://www.jobplanet.co.kr/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 <b>라이브러리</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import platform\n",
    "\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver import ActionChains\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.common.by import By\n",
    "\n",
    "#한글 폰트\n",
    "if platform.system()== 'Windows' :\n",
    "    plt.rc('font', family='NanumGothic')\n",
    "else:\n",
    "    plt.rc('font', family = 'AppleGothic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🛠 <b>알리오 공공기관 코드 크롤링</b>\n",
    "\n",
    "\n",
    "알리오 370여개 공공기관 스크립트 작동 내부 url 코드 크롤링\n",
    "\n",
    "\n",
    "알리오 - [항목 별 공시] - [직원 평균보수 현황] 정보는 문서 스크립트로 동작, 바로 크롤링 할 수 없음.\n",
    "\n",
    "\n",
    "각 공공기관 별 내부 url 코드에서 규칙을 찾아 크롤링 (C0001 ~ C1370)\n",
    "\n",
    "\n",
    "+ https://alio.go.kr/item/itemReportTerm.do?apbaId=C0001&reportFormRootNo=20601#toc-124\n",
    "\n",
    "\n",
    "script 에 disclosureNo('2021041302190478') 형식의 공개 번호 발견, html 문서에 직접 접근해 크롤링 할 수 있게 됨.\n",
    "\n",
    "\n",
    "+ https://alio.go.kr/upload/disclosure/2021/04/13/2021041302190478/doc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 알리오 372개 공공기관 내부 url 코드 크롤링 (7분 40초 걸림)\n",
    "\n",
    "codedict = {\"institution\":[], \"code\":[]}\n",
    "\n",
    "for i in range(1, 1370):\n",
    "    \n",
    "    if i < 10 :\n",
    "        urlcode = 'C000{}'.format(i)\n",
    "    elif 10 <= i | i < 100 :\n",
    "        urlcode = 'C00{}'.format(i)\n",
    "    elif 100 <= i | i < 1000 :\n",
    "        urlcode = 'C0{}'.format(i)\n",
    "    elif 1000 <= i | i < 10000 :\n",
    "        urlcode = 'C{}'.format(i)\n",
    "\n",
    "    url = 'https://alio.go.kr/item/itemReportTerm.do?apbaId={}&reportFormRootNo=20601'.format(urlcode)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        #print(response.status_code)\n",
    "    else :\n",
    "        print(response.status_code)\n",
    "\n",
    "    institution = soup.select_one('#p_header_wrap > div.hl_area > div > div > span')\n",
    "\n",
    "    if institution != None:\n",
    "        codedict['institution'].append(institution.text)\n",
    "        codedict['code'].append(urlcode)\n",
    "        print('institution: ' + institution.text + ', code: ' + urlcode)\n",
    "\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추출한 url 코드 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(codedict)\n",
    "df\n",
    "\n",
    "# 한국광해광업공단(2021.12.08 지정) 이전 데이터 없음 -> 삭제\n",
    "# **한국율도 데이터 없음 -> 삭제\n",
    "df.drop(index=226, axis=0, inplace=True)\n",
    "df.drop(index=371, axis=0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# csv 파일로 저장\n",
    "df.to_csv('institution_code.csv', index=False)\n",
    "\n",
    "# 제대로 저장되었는지 확인\n",
    "institution_code = pd.read_csv('institution_code.csv')\n",
    "institution_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institution_code = pd.read_csv('institution_code.csv')\n",
    "institution_code\n",
    "institution_code[institution_code['institution']=='**한국율도']\n",
    "\n",
    "institution_code.drop(index=226, axis=0, inplace=True)\n",
    "institution_code.drop(index=371, axis=0, inplace=True)\n",
    "institution_code.reset_index(drop=True, inplace=True)\n",
    "institution_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🛠 <b>알리오 정보 크롤링</b>\n",
    "disclosureNo('2021041302190478') 형식의 공개 번호를 통해 알리오 html 문서 크롤링 \n",
    "\n",
    "https://alio.go.kr/upload/disclosure/2021/04/13/2021041302190478/doc.html\n",
    "\n",
    "+ 신입사원 초임 (new_sal)\n",
    "+ 직원 평균연봉 (avg_sal)\n",
    "+ 평균 근속연수 (y_service)\n",
    ">각각 6년치 데이터 크롤링(2016, 2017, 2018, 2019, 2020, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetAlioInfo :\n",
    "    \n",
    "    def __init__(self, keyword) :\n",
    "        urlword = institution_code[institution_code['institution']==keyword]['code'].values[0]\n",
    "\n",
    "        url = 'https://alio.go.kr/item/itemReportTerm.do?apbaId={}&reportFormRootNo=20601'.format(urlword)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        html = response.text\n",
    "        self.soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        script = self.soup.select(\"body > script:nth-child(4)\")\n",
    "        str(script[0])\n",
    "        regex=re.compile(\"disclosureNo:\\\"(\\d+)\\\"\")\n",
    "        disclosureNo = regex.findall(str(script[0]))[0]\n",
    "        disclosureyear = disclosureNo[:4]\n",
    "        disclosuremonth = disclosureNo[4:6]\n",
    "        disclosureday = disclosureNo[6:8]\n",
    "\n",
    "        url = 'https://alio.go.kr/upload/disclosure/{}/{}/{}/{}/doc.html'.format(disclosureyear, disclosuremonth, disclosureday, disclosureNo)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            html = response.text\n",
    "            self.soup = BeautifulSoup(html, 'html.parser')\n",
    "            #print(response.status_code)\n",
    "        else :\n",
    "            print(response.status_code)\n",
    "    \n",
    "    def get_new_sal(self) :\n",
    "        address = self.soup.find(\"a\", text=\"2. 신입사원 초임\").findNext(text=\"합계\").parent.parent\n",
    "        new_sal = address.text.strip().split('\\n')\n",
    "        new_sal[0] = '신입사원 초봉'\n",
    "        return(new_sal)\n",
    "\n",
    "    def get_avg_sal(self) :\n",
    "        address = self.soup.find(\"td\", text=\"정규직(일반정규직)\").findNext(text=\"1인당 평균 보수액\").parent.parent\n",
    "        avg_sal = address.text.strip().split('\\n')\n",
    "        return(avg_sal)\n",
    "\n",
    "    def get_y_service(self) :\n",
    "        address = self.soup.find(\"td\", text=\"정규직(일반정규직)\").findNext(text=\"평균근속연수(개월)\").parent.parent\n",
    "        y_service = address.text.strip().split('\\n')\n",
    "        return(y_service)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 알리오 직원 평균연봉 크롤링+저장\n",
    "직원 평균연봉(avg_sal) -> alio_avg_sal.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sal_dict = {\"institution\":[], \"avg16\":[], \"avg17\":[], \"avg18\":[], \"avg19\":[], \"avg20\":[], \"avg21\":[]}\n",
    "\n",
    "i = 1\n",
    "for keyword in institution_code['institution']:\n",
    "    a = GetAlioInfo(keyword)\n",
    "    templist = a.get_avg_sal()\n",
    "    avg_sal_dict['institution'].append(keyword)\n",
    "    avg_sal_dict['avg16'].append(templist[1].strip().replace(',',''))\n",
    "    avg_sal_dict['avg17'].append(templist[2].strip().replace(',',''))\n",
    "    avg_sal_dict['avg18'].append(templist[3].strip().replace(',',''))\n",
    "    avg_sal_dict['avg19'].append(templist[4].strip().replace(',',''))\n",
    "    avg_sal_dict['avg20'].append(templist[5].strip().replace(',',''))\n",
    "    avg_sal_dict['avg21'].append(templist[6].strip().replace(',',''))\n",
    "    percentage = round(i / (len(institution_code['institution'])+1) * 100, 2)\n",
    "    print(percentage,'% ', keyword, templist[1:6])\n",
    "    i += 1\n",
    "\n",
    "df = pd.DataFrame(avg_sal_dict)\n",
    "df.to_csv('alio_avg_sal.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 알리오 신입사원 초봉 크롤링+저장\n",
    "신입사원 초봉(new_sal) -> alio_new_sal.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sal_dict = {\"institution\":[], \"new16\":[], \"new17\":[], \"new18\":[], \"new19\":[], \"new20\":[], \"new21\":[]}\n",
    "\n",
    "i = 1\n",
    "for keyword in institution_code['institution']:\n",
    "    a = GetAlioInfo(keyword)\n",
    "    templist = a.get_new_sal()\n",
    "    new_sal_dict['institution'].append(keyword)\n",
    "    new_sal_dict['new16'].append(templist[1].strip().replace(',',''))\n",
    "    new_sal_dict['new17'].append(templist[2].strip().replace(',',''))\n",
    "    new_sal_dict['new18'].append(templist[3].strip().replace(',',''))\n",
    "    new_sal_dict['new19'].append(templist[4].strip().replace(',',''))\n",
    "    new_sal_dict['new20'].append(templist[5].strip().replace(',',''))\n",
    "    new_sal_dict['new21'].append(templist[6].strip().replace(',',''))\n",
    "    percentage = round(i / (len(institution_code['institution'])+1) * 100, 2)\n",
    "    print(percentage,'% ', keyword, templist[1:6])\n",
    "    i += 1\n",
    "    \n",
    "df = pd.DataFrame(new_sal_dict)\n",
    "df.to_csv('alio_new_sal.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 알리오 평균 근속년수 크롤링+저장\n",
    "평균 근속년수(y_service) -> alio_y_service.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_service_dict = {\"institution\":[], \"ser16\":[], \"ser17\":[], \"ser18\":[], \"ser19\":[], \"ser20\":[], \"ser21\":[]}\n",
    "\n",
    "i = 1\n",
    "for keyword in institution_code['institution']:\n",
    "    a = GetAlioInfo(keyword)\n",
    "    templist = a.get_y_service()\n",
    "    y_service_dict['institution'].append(keyword)\n",
    "    y_service_dict['ser16'].append(templist[1].strip().replace(',',''))\n",
    "    y_service_dict['ser17'].append(templist[2].strip().replace(',',''))\n",
    "    y_service_dict['ser18'].append(templist[3].strip().replace(',',''))\n",
    "    y_service_dict['ser19'].append(templist[4].strip().replace(',',''))\n",
    "    y_service_dict['ser20'].append(templist[5].strip().replace(',',''))\n",
    "    y_service_dict['ser21'].append(templist[6].strip().replace(',',''))\n",
    "    percentage = round(i / (len(institution_code['institution'])+1) * 100, 2)\n",
    "    print(percentage,'% ', keyword, templist[1:6])\n",
    "    i += 1\n",
    "\n",
    "df = pd.DataFrame(y_service_dict)\n",
    "df.to_csv('alio_y_service.csv')\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🛠<b> 잡알리오 </b>\n",
    "\n",
    "https://job.alio.go.kr/recruit.do\n",
    "\n",
    "공공기관 채용 정보 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {\"institution\":[], \"title\":[], \"region\":[], \"type\":[], \"start_date\":[], \"end_date\":[], \"new_sal\":[], \"avg_sal\":[], \"rate\":[]}\n",
    "\n",
    "def current_employment():\n",
    "\n",
    "    classification = input(\"\"\"\n",
    "    직종을 선택해 주세요: \n",
    "    1. 경영사무,     2. 서비스 ,    3. ICT,    4. 교육/연구,    5. 산업,    6. 전부\"\"\")\n",
    "    if classification == '경영사무':\n",
    "        classification = '&detail_code=R600001&detail_code=R600002&detail_code=R600003'\n",
    "    elif classification == '서비스':\n",
    "        classification = '&detail_code=R600005&detail_code=R600006&detail_code=R600007&detail_code=R600008&detail_code=R600009&detail_code=R600010&detail_code=R600011&detail_code=R600012&detail_code=R600013'\n",
    "    elif classification == 'ICT':\n",
    "        classification = '&detail_code=R600019&detail_code=R600020'\n",
    "    elif classification == '교육/연구':\n",
    "        classification = '&detail_code=R600004&detail_code=R600025'\n",
    "    elif classification == '산업':\n",
    "        classification = '&detail_code=R600014&detail_code=R600015&detail_code=R600016&detail_code=R600017&detail_code=R600018&detail_code=R600021&detail_code=R600022&detail_code=R600023&detail_code=R600024'\n",
    "    elif classification == '전부':\n",
    "        classification = ''\n",
    "    \n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "\n",
    "        url = 'https://job.alio.go.kr/recruit.do?pageNo={}&idx=&recruitYear=&recruitMonth={}&work_type=R1010&work_type=R1070&s_date=2021.12.08&e_date=2022.02.08&org_type=&org_name=&ing=2&title=&order=REG_DATE#'.format(page, classification)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            html = response.text\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            #print(response.status_code)\n",
    "        else :\n",
    "            print(response.status_code)\n",
    "\n",
    "        tbody = soup.select_one('#frm > table > tbody')\n",
    "        trs = tbody.select('tr')\n",
    "        \n",
    "        if len(tbody.text.strip()) == 0:\n",
    "            #print('neu~')  # 내용 없는 페이지까지 출력 후 확인용\n",
    "            break\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.select(\"td\")\n",
    "            dictionary[\"institution\"].append(tds[3].text.replace('재단법인', '(재)').strip())\n",
    "            dictionary[\"title\"].append(tds[2].text.replace('\\t', '').replace('\\r', '').replace('\\n', '').strip())\n",
    "            dictionary[\"region\"].append(tds[4].text.replace('\\t', '').replace('\\r', '').replace('\\n', '').strip())\n",
    "            dictionary[\"type\"].append(tds[5].text.replace('\\t', '').replace('\\r', '').replace('\\n', '').strip())\n",
    "            dictionary[\"start_date\"].append(tds[6].text)\n",
    "            dictionary[\"end_date\"].append(tds[7].text)\n",
    "\n",
    "            # JobPlanet 리뷰\n",
    "            try:\n",
    "                keyword = tds[3].text.replace('재단법인', '(재)').strip()\n",
    "                url = 'https://www.jobplanet.co.kr/search?_rs_act=search_history&_rs_con=seach&category=search_new&query={}'.format(keyword)\n",
    "\n",
    "                response = requests.get(url)\n",
    "\n",
    "                response.raise_for_status()\n",
    "                if response.status_code == 200:\n",
    "                    html = response.text\n",
    "                    soup = BeautifulSoup(html, 'html.parser')\n",
    "                    #print(response.status_code)\n",
    "                else :\n",
    "                    print(response.status_code)\n",
    "\n",
    "                result_card = soup.select_one('#mainContents > div:nth-child(1) > div > div.result_company_card > div.is_company_card > div:nth-child(1)')\n",
    "                rate = result_card.select_one('#mainContents > div:nth-child(1) > div > div.result_company_card > div.is_company_card > div:nth-child(1) > span.rate_ty02')\n",
    "                dictionary['rate'].append(float(rate.text.strip()))\n",
    "                print(rate.text)\n",
    "            except:\n",
    "                dictionary['rate'].append(None)\n",
    "        page += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_employment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dictionary)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrate = pd.concat([df['institution'], df['rate'], df['new_sal'],df['avg_sal']], axis=1)\n",
    "dfrate.drop_duplicates(inplace=True)\n",
    "dfrate.dropna(inplace=True)\n",
    "dfrate_top5 = dfrate.sort_values(['rate'], ascending=False).head(5)\n",
    "dfrate_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=15)\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "x = np.arange(len(dfrate_top5['institution']))\n",
    "\n",
    "plt.bar(x-0, dfrate_top5['rate']*10000, label='rate', color = 'b', width=0.2)\n",
    "plt.bar(x+0.2, dfrate_top5['new_sal'], label='new_sal', color = 'r', width=0.2)\n",
    "plt.bar(x+0.4, dfrate_top5['avg_sal'], label='avg_sal', color = 'g', width=0.2)\n",
    "plt.xticks(x, dfrate_top5['institution'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dictionary = {\"institution\":[], \"title\":[], \"region\":[], \"type\":[], \"start_date\":[], \"end_date\":[]}\n",
    "\n",
    "def get_all_employment():\n",
    "\n",
    "    classification = input(\"\"\"\n",
    "    직종을 선택해 주세요:\n",
    "    1. 경영사무\n",
    "    2. 서비스\n",
    "    3. ICT\n",
    "    4. 교육/연구 \"\"\")\n",
    "    if classification == '경영사무':\n",
    "        classification = '&detail_code=R600001&detail_code=R600002&detail_code=R600003'\n",
    "    elif classification == '서비스':\n",
    "        classification = '&detail_code=R600005&detail_code=R600006&detail_code=R600007&detail_code=R600008&detail_code=R600009&detail_code=R600010&detail_code=R600011&detail_code=R600012&detail_code=R600013'\n",
    "    elif classification == 'ICT':\n",
    "        classification = '&detail_code=R600019&detail_code=R600020'\n",
    "    elif classification == '교육/연구':\n",
    "        classification = '&detail_code=R600004&detail_code=R600025'\n",
    "    elif classification == '산업':\n",
    "        classification = '&detail_code=R600014&detail_code=R600015&detail_code=R600016&detail_code=R600017&detail_code=R600018&detail_code=R600021&detail_code=R600022&detail_code=R600023&detail_code=R600024'\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "\n",
    "        url = 'https://job.alio.go.kr/recruit.do?pageNo={}&idx=&recruitYear=&recruitMonth={}&work_type=R1010&work_type=R1070&s_date=2016.01.01&e_date=2022.02.08&org_type=&org_name=&title=&order=REG_DATE#'.format(page, classification)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            html = response.text\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            #print(response.status_code)\n",
    "        else :\n",
    "            print(response.status_code)\n",
    "\n",
    "        tbody = soup.select_one('#frm > table > tbody')\n",
    "        trs = tbody.select('tr')\n",
    "        \n",
    "        if len(tbody.text.strip()) == 0:\n",
    "            print('neu~')  # 내용 없는 페이지까지 출력 후 확인용\n",
    "            break\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.select(\"td\")\n",
    "            all_dictionary[\"institution\"].append(tds[3].text.replace('재단법인', '(재)').strip())\n",
    "            all_dictionary[\"title\"].append(tds[2].text.replace('\\t', '').replace('\\r', '').replace('\\n', '').strip())\n",
    "            all_dictionary[\"region\"].append(tds[4].text.replace('\\t', '').replace('\\r', '').replace('\\n', '').strip())\n",
    "            all_dictionary[\"type\"].append(tds[5].text.replace('\\t', '').replace('\\r', '').replace('\\n', '').strip())\n",
    "            all_dictionary[\"start_date\"].append(tds[6].text)\n",
    "            all_dictionary[\"end_date\"].append(tds[7].text)\n",
    "\n",
    "        page += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_employment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_dictionary)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_date'] = pd.to_datetime(df['start_date'], yearfirst= True)\n",
    "df['end_date'] = pd.to_datetime(df['end_date'], yearfirst= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "monthlist = []\n",
    "\n",
    "\n",
    "for i in range(1, 13):\n",
    "    monthlist.append(df[df['end_date'].dt.month==i]['institution'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "plt.bar(month, monthlist)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "099c82bb4ace82ade8ea00d06692c6005c84f3239a96c9207fc6992d929102eb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
